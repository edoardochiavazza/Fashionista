# -*- coding: utf-8 -*-
"""Fashionista.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uo2upC8a-Tr0jhIZ5G1MXXXmf4-wWhBz
"""

!nvidia-smi

"""Config Tensorflow and Keras"""

!pip uninstall tensorflow
!pip install tensorflow==1.3.0

!pip install keras==2.0.8

"""Set Path and libraries for the training"""

!git clone https://www.github.com/matterport/Mask_RCNN.git
os.chdir('Mask_RCNN')

!rm -rf .git # to prevent an error when the kernel is committed
!rm -rf images assets # to prevent displaying images at the bottom of a kernel

!wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5
!ls -lh mask_rcnn_coco.h5

COCO_WEIGHTS_PATH = 'mask_rcnn_coco.h5'

!apt-get -qq install -y libarchive-dev && pip install -U libarchive
!apt-get -qq install python-cartopy python3-cartopy

import os
import scipy
import cython
import h5py
import imgaug
import IPython
import gc
import sys
import json
import pydot
import glob
import random
from pathlib import Path
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import itertools
from tqdm import tqdm
from imgaug import augmenters as iaa
from sklearn.model_selection import StratifiedKFold, KFold
import libarchive
import pydot
import cartopy
import tensorflow as tf
from skimage import io

DATA_DIR = Path("/content/drive/My Drive/imaterialist-fashion-2019-FGVC6")
ROOT_DIR = Path("/content/drive/My Drive/imaterialist-fashion-2019-FGVC6")
COCO_WEIGHTS_PATH = '/content/drive/My Drive/imaterialist-fashion-2019-FGVC6/Mask_RCNN/mask_rcnn_coco.h5'
# For demonstration purpose, the classification ignores attributes (only categories),
# and the image size is set to 512, which is the same as the size of submission masks
NUM_CATS = 46
IMAGE_SIZE = 512

sys.path.append(str(ROOT_DIR/'Mask_RCNN'))
from mrcnn.config import Config
from mrcnn import utils
import mrcnn.model as modellib
from mrcnn import visualize
from mrcnn.model import log

os.chdir('/content/drive/My Drive/imaterialist-fashion-2019-FGVC6/Mask_RCNN')
!rm -rf .git # to prevent an error when the kernel is committed
!rm -rf images assets # to prevent displaying images at the bottom of a kernel

"""The first confing use resnet50 """

class FashionConfig(Config):
    NAME = "fashion"
    NUM_CLASSES = NUM_CATS + 1 # +1 for the background class
    
    GPU_COUNT = 1
    IMAGES_PER_GPU = 8 # a memory error occurs when IMAGES_PER_GPU is too high
    
    BACKBONE = 'resnet50'
    
    IMAGE_MIN_DIM = IMAGE_SIZE
    IMAGE_MAX_DIM = IMAGE_SIZE    
    IMAGE_RESIZE_MODE = 'none'
    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)
    #DETECTION_NMS_THRESHOLD = 0.0
    
    # STEPS_PER_EPOCH should be the number of instances 
    # divided by (GPU_COUNT*IMAGES_PER_GPU), and so should VALIDATION_STEPS;
    # however, due to the time limit, I set them so that this kernel can be run in 9 hours
    STEPS_PER_EPOCH = 50
    VALIDATION_STEPS = 50
    
config = FashionConfig()
config.display()

"""Instead the second use resnet101. Keep attenction to the loss function, because it can increase the value"""

class FashionConfig(Config):
    NAME = "fashion"
    NUM_CLASSES = NUM_CATS + 1 # +1 for the background class
    
    GPU_COUNT = 1
    IMAGES_PER_GPU = 8 # a memory error occurs when IMAGES_PER_GPU is too high
    
    BACKBONE = 'resnet101'
    
    IMAGE_MIN_DIM = IMAGE_SIZE
    IMAGE_MAX_DIM = IMAGE_SIZE    
    IMAGE_RESIZE_MODE = 'none'
    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)
    #DETECTION_NMS_THRESHOLD = 0.0
    
    # STEPS_PER_EPOCH should be the number of instances 
    # divided by (GPU_COUNT*IMAGES_PER_GPU), and so should VALIDATION_STEPS;
    # however, due to the time limit, I set them so that this kernel can be run in 9 hours
    STEPS_PER_EPOCH = 50
    VALIDATION_STEPS = 50
    
config = FashionConfig()
config.display()

with open(DATA_DIR/"label_descriptions.json") as f:
    label_descriptions = json.load(f)
label_names = [x['name'] for x in label_descriptions['categories']]

PATH_DIR_IMG_REDUCED = '/content/drive/My Drive/imaterialist-fashion-2019-FGVC6/image_c' #here place the root of the directory where u want the images subset 
PATH_TO_CSV = None # root of the original csv file  
PATH_TO_IMG = None # root of the original directory of the images 
PATH_TO_CSV_REDUCED: '/content/drive/My Drive/imaterialist-fashion-2019-FGVC6/train_prova.csv' #root of csv where u want the csv description of images subset

import pandas as pd
import json 
import shutil
import numpy as np

class ReduceDataFrame():
  MAX_IMAGE = 100
  i = 0
  df1 = pd.DataFrame()
  label_id = [x['id'] for x in label_descriptions['attributes']]
  fields = ['ImageId', 'EncodedPixels', 'Height', 'Width', 'ClassId']
  df = pd.read_csv(PATH_TO_CSV, skipinitialspace=True, usecols=fields)
  df2=df['ClassId'].str.split("_",expand = True)
  df['index'] = df.index.values
  df2['index'] = df2.index.values
  df2 = pd.merge(df, df2, on="index")
  df2=df2.drop(columns=['ClassId', 'index','EncodedPixels', 'Height', 'Width'])
  for num_img in range(0, MAX_IMAGE):
      for id_category in label_id:
          arr = df2.to_numpy()
          find_image = False
          for n_row in range(0,len(arr)):
              for n_column in range(1, np.size(arr, 1)):
                  if arr[n_row][n_column] == str(id_category):
                      i+=1
                      image_id = arr [n_row][0]
                      print(arr[n_row])
                      find_image = True
                      df1=df1.append(df.loc[df['ImageId'] == image_id])
                      shutil.copyfile((PATH_TO_IMG + image_id),(PATH_TO_IMG_REDUCED + image_id))
                      df2 = df2[df2['ImageId'] != image_id]
                      break;
              if(find_image == True):
                  break;    
  df1.to_csv(PATH_TO_CSV_REDUCED)

ReduceDataFrame()

segment_df = pd.read_csv("/content/drive/My Drive/imaterialist-fashion-2019-FGVC6/train_prova.csv")
multilabel_percent = len(segment_df[segment_df['ClassId'].str.contains('_')])/len(segment_df)*100
print(f"Segments that have attributes: {multilabel_percent:.2f}%")

segment_df['CategoryId'] = segment_df['ClassId'].astype(str).str.split('_').str[0]

print("Total segments: ", len(segment_df))
segment_df.head()

image_df = segment_df.groupby('ImageId')['EncodedPixels', 'CategoryId'].agg(lambda x: list(x))
size_df = segment_df.groupby('ImageId')['Height', 'Width'].mean()
image_df = image_df.join(size_df, on='ImageId')
print("Total images: ", len(image_df))
image_df.head()

def resize_image(image_path):
    img = cv2.imread(image_path)
    #cv2_imshow(img)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)  
    return img

class FashionDataset(utils.Dataset):

    def __init__(self, df):
        super().__init__(self)
        
        # Add classes
        for i, name in enumerate(label_names):
            self.add_class("fashion", i+1, name)
        
        # Add images 
        for i, row in df.iterrows():
            self.add_image("fashion", 
                           image_id=row.name, 
                           path=str(DATA_DIR/'image_c'/row.name), 
                           labels=row['CategoryId'],
                           annotations=row['EncodedPixels'], 
                           height=row['Height'], width=row['Width'])

    def image_reference(self, image_id):
        info = self.image_info[image_id]
        return info['path'], [label_names[int(x)] for x in info['labels']]
    
    def load_image(self, image_id):
        return resize_image(self.image_info[image_id]['path'])

    def load_mask(self, image_id):
        info = self.image_info[image_id]
                
        mask = np.zeros((IMAGE_SIZE, IMAGE_SIZE, len(info['annotations'])), dtype=np.uint8)
        labels = []
        
        for m, (annotation, label) in enumerate(zip(info['annotations'], info['labels'])):
            sub_mask = np.full(info['height']*info['width'], 0, dtype=np.uint8)
            annotation = [int(x) for x in annotation.split(' ')]
            
            for i, start_pixel in enumerate(annotation[::2]):
                sub_mask[start_pixel: start_pixel+annotation[2*i+1]] = 1

            sub_mask = sub_mask.reshape((info['height'], info['width']), order='F')
            sub_mask = cv2.resize(sub_mask, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)
            
            mask[:, :, m] = sub_mask
            labels.append(int(label)+1)
            
        return mask, np.array(labels)

"""Try dataset and Mask_RCNN algorithm"""

dataset = FashionDataset(image_df)
dataset.prepare()

for i in range(6):
    image_id = random.choice(dataset.image_ids)
    print(dataset.image_reference(image_id))
    
    image = dataset.load_image(image_id)
    mask, class_ids = dataset.load_mask(image_id)
    visualize.display_top_masks(image, mask, class_ids, dataset.class_names, limit=4)

"""Training part"""

# This code partially supports k-fold training, 
# you can specify the fold to train and the total number of folds here
FOLD = 0
N_FOLDS = 5

kf = KFold(n_splits=N_FOLDS, random_state=42, shuffle=True)
splits = kf.split(image_df) # ideally, this should be multilabel stratification

def get_fold():    
    for i, (train_index, valid_index) in enumerate(splits):
        if i == FOLD:
            return image_df.iloc[train_index], image_df.iloc[valid_index]
        
train_df, valid_df = get_fold()

train_dataset = FashionDataset(train_df)
train_dataset.prepare()

valid_dataset = FashionDataset(valid_df)
valid_dataset.prepare()
valid_df.head()
image_df.keys()

train_segments = np.concatenate(train_df['CategoryId'].values).astype(int)
print("Total validation images: ", len(valid_df))
print("Total train segments: ", len(train_segments))

plt.figure(figsize=(12, 3))
values, counts = np.unique(train_segments, return_counts=True)
plt.bar(values, counts)
plt.xticks(values, label_names, rotation='vertical')
plt.show()

valid_segments = np.concatenate(valid_df['CategoryId'].values).astype(int)
print("Total train images: ", len(valid_df))
print("Total validation segments: ", len(valid_segments))

plt.figure(figsize=(12, 3))
values, counts = np.unique(valid_segments, return_counts=True)
plt.bar(values, counts)
plt.xticks(values, label_names, rotation='vertical')
plt.show()

# Note that any hyperparameters here, such as LR, may still not be optimal
LR = 1e-4 #advice: decrease the LR during the epoch for obtain best results
EPOCHS = [15 30, 45]

import warnings 
warnings.filterwarnings("ignore")

model = modellib.MaskRCNN(mode='training', config=config, model_dir='/content/drive/My Drive/imaterialist-fashion-2019-FGVC6/checkpoint2')
model_inference = modellib.MaskRCNN(mode= 'inference', config=config, model_dir='/content/drive/My Drive/imaterialist-fashion-2019-FGVC6/checkpoint')

mean_average_precision_callback = modellib.MeanAveragePrecisionCallback(model,
model_inference, valid_dataset, calculate_map_at_every_X_epoch=2, dataset_limit=50, verbose=1) #place batch_size equal to 1 if u want use mAP

model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[
    'mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask'])

"""Use one of the two data augmentation function

"""

augmentation = iaa.Sequential([
    iaa.Fliplr(0.5) # only horizontal flip here
])

augmentation = iaa.Sequential([
    iaa.OneOf([ # rotate
        iaa.Affine(rotate=0),
        iaa.Affine(rotate=90),
        iaa.Affine(rotate=180),
        iaa.Affine(rotate=270),
    ]),
    iaa.Fliplr(0.5),
    iaa.Flipud(0.5),
    iaa.OneOf([ # brightness or contrast
        iaa.Multiply((0.9, 1.1)),
        iaa.ContrastNormalization((0.9, 1.1)),
    ]),
    iaa.OneOf([ # blur or sharpen
        iaa.GaussianBlur(sigma=(0.0, 0.3)),
        iaa.Sharpen(alpha=(0.0, 0.3)),
    ]),
])

"""First train only the heads layers, because we start from a pre-trained weights"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model.train(train_dataset, valid_dataset,
#             learning_rate=LR,
#             epochs=EPOCHS[1],
#             layers='heads',
#             augmentation=augmentation,
#             #custom_callbacks= [mean_average_precision_callback]
#             )
# history = model.keras_model.history.history

"""Now train all layers"""

model.train(train_dataset, valid_dataset,
            learning_rate=LR,
            epochs=EPOCHS[2],
            layers='all',
            augmentation=augmentation
            )
new_history = model.keras_model.history.history
for k in new_history: history[k] = history[k] + new_history[k]

"""Reduce LR and restart train all layers"""

model.train(train_dataset, valid_dataset,
            learning_rate=LR,
            epochs=EPOCHS[2],
            layers='all',
            augmentation=augmentation
            )
new_history = model.keras_model.history.history
for k in new_history: history[k] = history[k] + new_history[k]

"""Let's visualize training history and choose the best epoch."""

epochs = range(EPOCHS[-1])
plt.figure(figsize=(18, 6))
plt.subplot(131)
plt.plot(epochs, history['loss'], label="train loss")
plt.plot(epochs, history['val_loss'], label="valid loss")
plt.legend()
plt.subplot(132)
plt.plot(epochs, history['mrcnn_class_loss'], label="train class loss")
plt.plot(epochs, history['val_mrcnn_class_loss'], label="valid class loss")
plt.legend()
plt.subplot(133)
plt.plot(epochs, history['mrcnn_mask_loss'], label="train mask loss")
plt.plot(epochs, history['val_mrcnn_mask_loss'], label="valid mask loss")
plt.legend()

plt.show()

best_epoch = np.argmin(history["val_loss"]) + 1
print("Best epoch: ", best_epoch)
print("Valid loss: ", history["val_loss"][best_epoch-1])

"""**Predict:**

The final step is to use model to predict test data.
"""

glob_list = glob.glob(f'/kaggle/working/fashion*/mask_rcnn_fashion_{best_epoch:04d}.h5')
model_path = glob_list[0] if glob_list else ''

"""This cell defines InferenceConfig and loads the best trained model.


"""

class InferenceConfig(FashionConfig):
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1

inference_config = InferenceConfig()

model = modellib.MaskRCNN(mode='inference', 
                          config=inference_config,
                          model_dir=ROOT_DIR)

assert model_path != '', "Provide path to trained weights"
print("Loading weights from ", model_path)
model.load_weights(model_path, by_name=True)

"""Then, load the submission data."""

sample_df = pd.read_csv(DATA_DIR/"train_reduced.csv")
sample_df.head()

"""Some helper functions."""

valid_df.reset_index(inplace=True)
train_df.reset_index(inplace=True)

"""Now can see the result. Sample images contain both fashion models and predictions from the Mask R-CNN model."""

for i in range(9):
    image_id = train_df.sample()['ImageId'].values[0]
    image_path = str(DATA_DIR/'image_c'/image_id) 
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    result = model.detect([resize_image(image_path)])
    r = result[0]
    if r['masks'].size > 0:
        masks = np.zeros((img.shape[0], img.shape[1], r['masks'].shape[-1]), dtype=np.uint8)
        for m in range(r['masks'].shape[-1]):
            masks[:, :, m] = cv2.resize(r['masks'][:, :, m].astype('uint8'), 
                                        (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)
        
        y_scale = img.shape[0]/IMAGE_SIZE
        x_scale = img.shape[1]/IMAGE_SIZE
        rois = (r['rois'] * [y_scale, x_scale, y_scale, x_scale]).astype(int)
        
        masks, rois = refine_masks(masks, rois)
    else:
        masks, rois = r['masks'], r['rois']
        
    visualize.display_instances(img, rois, masks, r['class_ids'], 
                                ['bg']+label_names, r['scores'],
                                title=image_id, figsize=(12, 12))